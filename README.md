# üõ∞Ô∏è TEMPO Air Quality Data Pipeline

Sistema automatizado para descargar y procesar datos de calidad del aire desde el sat√©lite TEMPO de la NASA.

**¬øQu√© hace este programa?**
- üì• Descarga autom√°ticamente datos de NO2 (di√≥xido de nitr√≥geno) y O3 (ozono) desde la NASA
- üìä Procesa los archivos y los convierte a formato JSON f√°cil de usar
- üå°Ô∏è Calcula concentraciones superficiales y niveles de calidad del aire (AQI)
- üì¶ Genera archivos listos para usar en tu aplicaci√≥n web o m√≥vil

> üöÄ **¬øPrimera vez usando el programa?** Lee la [**GU√çA DE INICIO R√ÅPIDO**](INICIO_RAPIDO.md) - 5 minutos paso a paso

---

## ÔøΩ GU√çA DE INSTALACI√ìN R√ÅPIDA

### Paso 1Ô∏è‚É£: Instalar Python

**Si no tienes Python instalado:**

1. Ve a [python.org/downloads](https://www.python.org/downloads/)
2. Descarga **Python 3.13** (o superior)
3. **IMPORTANTE:** Durante la instalaci√≥n, marca la casilla **"Add Python to PATH"**
4. Verifica la instalaci√≥n:
   ```powershell
   python --version
   ```
   Deber√≠a mostrar algo como: `Python 3.13.0`

---

### Paso 2Ô∏è‚É£: Descargar el Proyecto

**Opci√≥n A - Con Git (Recomendado):**
```powershell
git clone https://github.com/sxbast1anCZ/TEMPO-NC-Files-to-JSON.git
cd TEMPO-NC-Files-to-JSON
```

**Opci√≥n B - Sin Git:**
1. Ve al repositorio en GitHub
2. Click en "Code" ‚Üí "Download ZIP"
3. Descomprime el archivo
4. Abre PowerShell en esa carpeta

---

### Paso 3Ô∏è‚É£: Instalar Dependencias

Abre PowerShell en la carpeta del proyecto y ejecuta:

```powershell
pip install -r requirements.txt
```

Esto instalar√° autom√°ticamente todo lo necesario. **Toma un caf√©, tardar√° 2-3 minutos** ‚òï

---

### Paso 4Ô∏è‚É£: Crear Cuenta NASA (GRATIS)

El programa descarga datos desde la NASA, necesitas una cuenta gratuita:

1. Ve a [urs.earthdata.nasa.gov/users/new](https://urs.earthdata.nasa.gov/users/new)
2. Llena el formulario (es gratis, no pide tarjeta de cr√©dito)
3. Verifica tu email
4. **Guarda tu usuario y contrase√±a** (los necesitar√°s en el siguiente paso)

---

### Paso 5Ô∏è‚É£: Configurar Credenciales

1. En la carpeta del proyecto, crea un archivo llamado **`.env`** (exactamente as√≠, con el punto al inicio)
2. √Åbrelo con el Bloc de notas o cualquier editor de texto
3. Copia esto y **reemplaza con tus datos**:

```env
EARTHDATA_USERNAME=tu_usuario_de_nasa
EARTHDATA_PASSWORD=tu_contrase√±a_de_nasa
```

**Ejemplo:**
```env
EARTHDATA_USERNAME=juan.perez
EARTHDATA_PASSWORD=MiPassword123
```

4. **IMPORTANTE:** Guarda el archivo y NO lo compartas con nadie

> ÔøΩ **Tip:** Si no ves la extensi√≥n `.env`, aseg√∫rate de guardar como "Todos los archivos" en el Bloc de notas

---

### Paso 6Ô∏è‚É£: ¬°Probar que Todo Funciona!

Ejecuta este comando para verificar la instalaci√≥n:

```powershell
python verificar_flujo.py
```

**Si todo est√° bien, ver√°s:**
```
‚úÖ VERIFICACI√ìN COMPLETA EXITOSA
üéØ El flujo de procesamiento est√° funcionando correctamente
```

**Si hay errores:**
- Revisa que instalaste Python correctamente (Paso 1)
- Verifica que el archivo `.env` tenga tus credenciales correctas (Paso 5)
- Aseg√∫rate de estar en la carpeta correcta del proyecto

---

## üéØ C√ìMO USAR EL PROGRAMA

### Opci√≥n 1: Ejecutar Todo Autom√°ticamente (M√ÅS F√ÅCIL) ‚≠ê

Ejecuta este comando y d√©jalo trabajar:

```powershell
python pipeline_optimizado.py
```

**¬øQu√© hace?**
1. Descarga los archivos m√°s recientes desde NASA (~240 MB)
2. Los procesa y convierte a JSON
3. Calcula concentraciones y calidad del aire
4. Divide en archivos peque√±os para f√°cil manejo
5. Limpia archivos temporales

**Duraci√≥n:** ~5 minutos  
**Frecuencia recomendada:** Cada 3 horas (puedes configurar ejecuci√≥n autom√°tica abajo)

---

### Opci√≥n 2: Paso a Paso (Si quieres control manual)

```powershell
# 1. Descargar archivos desde NASA
python descargar_tempo_v2.py

# 2. Procesar archivos descargados
python extraer_datos.py

# 3. Convertir a concentraciones superficiales
python convertir_a_superficie.py

# 4. Dividir en archivos peque√±os (opcional)
python dividir_archivos.py
```

---

### Opci√≥n 3: Verificar y Ver Estad√≠sticas

```powershell
# Ver estad√≠sticas de los datos procesados
python mostrar_estadisticas.py

# Verificar que todo funciona bien
python verificar_flujo.py
```

---

## üìÅ ¬øD√ìNDE EST√ÅN LOS ARCHIVOS GENERADOS?

Despu√©s de ejecutar el programa, encontrar√°s los archivos aqu√≠:

```
TEMPO-NC-Files-to-JSON/
‚îî‚îÄ‚îÄ output/
    ‚îú‚îÄ‚îÄ SURFACE_NO2_*.json          ‚≠ê USAR ESTOS para NO2
    ‚îú‚îÄ‚îÄ SURFACE_O3_*.json           ‚≠ê USAR ESTOS para O3
    ‚îî‚îÄ‚îÄ chunks/
        ‚îú‚îÄ‚îÄ SURFACE_NO2_*_chunk_001.json
        ‚îú‚îÄ‚îÄ SURFACE_NO2_*_chunk_002.json
        ‚îî‚îÄ‚îÄ ... (archivos divididos)
```

**Archivos SURFACE_* son los que necesitas para tu aplicaci√≥n.**  
Contienen las concentraciones en ¬µg/m¬≥ (NO2) y ppb (O3) listas para usar.

---

## üìä FORMATO DE LOS DATOS

Los archivos JSON tienen esta estructura:

```json
{
  "metadata": {
    "scan_time": "2025-10-04T18:24:07Z",
    "product": "NO2",
    "points_extracted": 13358
  },
  "measurements": [
    {
      "latitude": 40.7128,
      "longitude": -74.0060,
      "timestamp": "2025-10-04T18:24:07Z",
      "pollutant": "NO2",
      "surface_concentration_ugm3": 45.32,
      "aqi": 92,
      "aqi_category": "Moderado",
      "quality_flag": 1.0
    }
  ]
}
```

**Campos importantes:**
- `latitude`, `longitude` - Ubicaci√≥n del punto
- `surface_concentration_ugm3` - Concentraci√≥n en ¬µg/m¬≥ (NO2)
- `tropospheric_concentration_ppb` - Concentraci√≥n en ppb (O3)
- `aqi` - √çndice de calidad del aire (0-500)
- `aqi_category` - Categor√≠a: "Bueno", "Moderado", etc.

---

## ‚è∞ CONFIGURAR EJECUCI√ìN AUTOM√ÅTICA (Opcional)

Para que el programa se ejecute solo cada 3 horas:

### En Windows:

1. **Abre PowerShell como Administrador** (click derecho ‚Üí "Ejecutar como administrador")
2. Ejecuta:
   ```powershell
   .\configurar_tarea_automatica.ps1
   ```
3. Confirma cuando te lo pida
4. ¬°Listo! El programa se ejecutar√° autom√°ticamente cada 3 horas

### Verificar la tarea autom√°tica:

```powershell
# Ver estado de la tarea
Get-ScheduledTask -TaskName "TEMPO_Data_Pipeline"

# Ejecutar manualmente
Start-ScheduledTask -TaskName "TEMPO_Data_Pipeline"

# Desactivar
Disable-ScheduledTask -TaskName "TEMPO_Data_Pipeline"
```

---

## üÜò SOLUCI√ìN DE PROBLEMAS COMUNES

### ‚ùå Error: "python no se reconoce como comando"

**Soluci√≥n:** Python no est√° en el PATH.
1. Desinstala Python
2. Vu√©lvelo a instalar marcando **"Add Python to PATH"**
3. Reinicia PowerShell

---

### ‚ùå Error: "Authentication failed"

**Soluci√≥n:** Credenciales incorrectas.
1. Verifica que el archivo `.env` existe
2. Revisa que usuario y contrase√±a sean correctos
3. Inicia sesi√≥n en [urs.earthdata.nasa.gov](https://urs.earthdata.nasa.gov) para confirmar que funcionan

---

### ‚ùå Error: "No se encontraron archivos .nc"

**Soluci√≥n:** No se descargaron archivos.
1. Verifica tu conexi√≥n a internet
2. Revisa las credenciales en `.env`
3. Ejecuta primero `python descargar_tempo_v2.py`

---

### ‚ùå Error: "ModuleNotFoundError: No module named 'netCDF4'"

**Soluci√≥n:** Dependencias no instaladas.
```powershell
pip install -r requirements.txt
```

---

### üÜò Ninguna soluci√≥n funciona

Ejecuta el verificador del sistema:

```powershell
python verificar_sistema.py
```

Te dir√° exactamente qu√© est√° fallando y c√≥mo arreglarlo.

---

## üìö DOCUMENTACI√ìN ADICIONAL

Si quieres profundizar m√°s:

- **`LIMPIEZA_COMPLETADA.md`** - Estructura del proyecto y archivos
- **`GUIA_GOOGLE_CLOUD.md`** - C√≥mo subir los datos a Google Cloud
- **`SCRIPTS.md`** - Descripci√≥n de cada script disponible

---

## üí° CONSEJOS Y MEJORES PR√ÅCTICAS

### ‚úÖ Recomendaciones:

1. **Ejecuta el pipeline cada 3 horas** para tener datos actualizados
2. **Usa los archivos SURFACE_*** - son los m√°s f√°ciles de usar
3. **Revisa las estad√≠sticas** con `python mostrar_estadisticas.py`
4. **Haz backup** de la carpeta `output/` peri√≥dicamente
5. **NO compartas** tu archivo `.env` con nadie

### üìä Tama√±o de Datos Esperado:

- **NO2:** ~15-60 MB por archivo (10,000-200,000 puntos)
- **O3:** ~1,000 MB por archivo (3,000,000+ puntos)
- **Chunks:** ~15-50 MB cada uno (m√°s f√°ciles de manejar)

### ‚è±Ô∏è Tiempos de Ejecuci√≥n:

- Descarga: ~2 minutos
- Procesamiento: ~2 minutos
- Total: ~5 minutos por ejecuci√≥n

---

## üéØ SIGUIENTES PASOS

**Una vez que tengas los datos:**

1. **Para aplicaci√≥n web:** Lee los archivos SURFACE_*.json directamente
2. **Para aplicaci√≥n m√≥vil:** Usa los chunks para cargar datos por partes
3. **Para an√°lisis:** Importa los JSON en pandas, Excel, o tu herramienta favorita
4. **Para API REST:** Sube a Google Cloud y crea endpoints (ver `GUIA_GOOGLE_CLOUD.md`)

---

## ü§ù CR√âDITOS Y AGRADECIMIENTOS

- **Datos:** NASA TEMPO Mission ([tempo.si.edu](https://tempo.si.edu))
- **API:** NASA Common Metadata Repository (CMR)
- **Proyecto:** Desarrollado por Sebastian
- **Versi√≥n de datos:** V04 (√∫ltima versi√≥n estable, octubre 2025)

---

## üìû SOPORTE

**¬øTienes problemas?**

1. Ejecuta `python verificar_sistema.py` primero
2. Revisa la secci√≥n "Soluci√≥n de Problemas" arriba
3. Contacta al desarrollador del proyecto

---

**√öltima actualizaci√≥n:** 4 de octubre de 2025  
**Versi√≥n:** 2.0 (Optimizada con Datacenter Features)


