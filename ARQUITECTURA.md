# ğŸ—ï¸ ARQUITECTURA DEL SISTEMA - TEMPO Data Pipeline

## ğŸ“‹ Resumen Ejecutivo

Sistema completo de procesamiento de datos satelitales TEMPO de NASA para anÃ¡lisis de calidad del aire, diseÃ±ado con arquitectura tipo datacenter para mÃ¡xima eficiencia y escalabilidad.

**Fecha de implementaciÃ³n:** 4 de Octubre 2025  
**VersiÃ³n:** 2.0 Optimizada  
**Estado:** âœ… ProducciÃ³n

---

## ğŸ¯ Objetivo del Sistema

Descargar, procesar y servir datos de calidad del aire (NO2 y O3) desde el satÃ©lite TEMPO de NASA cada 3 horas, con validaciÃ³n inteligente de calidad y respuestas optimizadas para API REST.

---

## ğŸ›ï¸ Arquitectura General

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NASA EARTHDATA (Fuente)                      â”‚
â”‚         CMR API + SessionWithHeaderRedirection Auth             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DESCARGADOR (descargar_tempo_v2.py)                â”‚
â”‚  â€¢ BÃºsqueda en CMR API                                          â”‚
â”‚  â€¢ Filtro por Collection ID (V04)                               â”‚
â”‚  â€¢ Descarga incremental (evita duplicados)                      â”‚
â”‚  â€¢ AutenticaciÃ³n OAuth NASA                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ .nc files
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EXTRACTOR (extraer_datos.py)                       â”‚
â”‚  â€¢ Lee archivos NetCDF (.nc)                                    â”‚
â”‚  â€¢ Extrae NO2 vertical columns + quality_flag                   â”‚
â”‚  â€¢ Extrae O3 total columns + quality_flag                       â”‚
â”‚  â€¢ Genera JSON estructurado                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ JSON raw
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          CONVERSOR (convertir_a_superficie.py)                  â”‚
â”‚  â€¢ Convierte columnas verticales â†’ superficie                   â”‚
â”‚  â€¢ Calcula AQI (Air Quality Index)                              â”‚
â”‚  â€¢ Aplica factores de conversiÃ³n cientÃ­ficos                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ JSON + AQI
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         VALIDADOR DE CALIDAD (quality_manager.py)               â”‚
â”‚  â€¢ Analiza distribuciÃ³n de quality_flag                         â”‚
â”‚  â€¢ Aplica estrategias: STRICT | MODERATE | PERMISSIVE           â”‚
â”‚  â€¢ FALLBACK automÃ¡tico si no hay datos buenos                   â”‚
â”‚  â€¢ Genera advertencias para API                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ JSON validado
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            CHUNKER (dividir_archivos.py)                        â”‚
â”‚  â€¢ Divide JSONs grandes en chunks de 50K puntos                 â”‚
â”‚  â€¢ ~14 MB por chunk (Ã³ptimo para Cloud)                         â”‚
â”‚  â€¢ Nomenclatura: *_chunk_NNN_of_TTT.json                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Chunks
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         OPTIMIZADOR (datacenter_optimizer.py)                   â”‚
â”‚  â€¢ Ãndice espacial (grid 1Â° x 1Â°)                               â”‚
â”‚  â€¢ Queries por bounding box                                     â”‚
â”‚  â€¢ CachÃ© de archivos procesados (MD5 hash)                      â”‚
â”‚  â€¢ Limpieza automÃ¡tica (>7 dÃ­as)                                â”‚
â”‚  â€¢ CompresiÃ³n opcional (gzip)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  API REST (api_example.py)                      â”‚
â”‚  â€¢ GET /api/v1/tempo/{pollutant}/latest                         â”‚
â”‚  â€¢ GET /api/v1/health                                           â”‚
â”‚  â€¢ Filtros: bbox, quality_threshold                             â”‚
â”‚  â€¢ Respuestas con validaciÃ³n de calidad                         â”‚
â”‚  â€¢ Recomendaciones automÃ¡ticas                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Componentes del Sistema

### 1. **Descargador AutomÃ¡tico** (`descargar_tempo_v2.py`)
**Responsabilidad:** Obtener archivos mÃ¡s recientes desde NASA

**CaracterÃ­sticas:**
- âœ… Usa NASA CMR (Common Metadata Repository) API
- âœ… AutenticaciÃ³n OAuth con `SessionWithHeaderRedirection`
- âœ… BÃºsqueda por Collection IDs:
  - NO2 V04: `C3685896872-LARC_CLOUD`
  - O3 V04: `C3685912131-LARC_CLOUD`
- âœ… Descarga incremental (skip si existe)
- âœ… Barra de progreso
- âœ… Timeout de 120s por archivo

**Output:** Archivos `.nc` en `tempo_data/`

---

### 2. **Extractor de Datos** (`extraer_datos.py`)
**Responsabilidad:** Convertir NetCDF a JSON estructurado

**Procesamiento:**
```python
NO2 L2: 
  - Variable: vertical_column_troposphere (molec/cmÂ²)
  - Quality flag: quality_flag (0-1)
  - Coordenadas: latitude, longitude (2D arrays)

O3 L3:
  - Variable: vertical_column_ozone (DU)
  - Quality flag: quality_flag (0-1)
  - Coordenadas: latitude, longitude (1D arrays)
```

**Filtrado:**
- âŒ Rechaza: quality_flag <= 0 (datos invÃ¡lidos)
- âœ… Acepta: quality_flag > 0 (datos vÃ¡lidos)

**Output:** `NO2_*.json`, `O3_*.json` en `output/`

---

### 3. **Conversor a Superficie** (`convertir_a_superficie.py`)
**Responsabilidad:** Convertir columnas verticales a concentraciones superficiales

**Conversiones cientÃ­ficas:**
```
NO2: 
  vertical_column (molec/cmÂ²) Ã— 0.75 â‰ˆ surface (Âµg/mÂ³)

O3:
  total_column (DU) Ã— 0.04 â‰ˆ tropospheric (ppb)
```

**CÃ¡lculo AQI:**
- NO2: EPA breakpoints (Âµg/mÂ³)
- O3: EPA breakpoints (ppb 8-hour avg simulado)

**Output:** `SURFACE_*.json` en `output/`

---

### 4. **Gestor de Calidad** (`quality_manager.py`) â­ **NUEVO**
**Responsabilidad:** ValidaciÃ³n inteligente con fallback automÃ¡tico

**Estrategias de filtrado:**
```python
STRICT      = 0.75  # Solo excelentes
MODERATE    = 0.50  # Buenos (default)
PERMISSIVE  = 0.01  # Cualquier vÃ¡lido
FALLBACK    = 0.00  # Todos (con advertencia)
```

**LÃ³gica de fallback:**
```
1. Intentar MODERATE (quality_flag >= 0.5)
   â””â”€> Si 0 resultados:
       2. Intentar PERMISSIVE (quality_flag > 0.01)
          â””â”€> Si 0 resultados:
              3. FALLBACK: Usar TODOS los datos
                 â””â”€> Marcar como "BAJA_CONFIANZA"
                 â””â”€> Agregar warning en respuesta API
```

**Respuesta para API:**
```json
{
  "data_quality": {
    "reliability": "BUENA" | "ACEPTABLE" | "BAJA_CONFIANZA",
    "fallback_used": true/false
  },
  "warning": "Los datos pueden tener baja confianza..."
}
```

---

### 5. **Optimizador Datacenter** (`datacenter_optimizer.py`) â­ **NUEVO**
**Responsabilidad:** Operaciones eficientes a escala

**Optimizaciones implementadas:**

#### a) **Ãndice Espacial**
```python
Grid 1Â° Ã— 1Â° para queries rÃ¡pidas
Ejemplo: 
  Cell "13,-89" contiene todos los puntos en:
    Lat [13.0, 14.0), Lon [-89.0, -88.0)

Query El Salvador (13-14Â°N, -90 a -87Â°W):
  - Sin Ã­ndice: O(N) - revisar todos los puntos
  - Con Ã­ndice: O(K) - solo celdas relevantes
  - Speedup: ~100x para regiones pequeÃ±as
```

#### b) **CachÃ© de archivos procesados**
```python
MD5 hash tracking para evitar reprocesamiento
.cache/FILENAME.hash â†’ "a3f5d8c2..."

Si hash no cambiÃ³ â†’ skip procesamiento
```

#### c) **Streaming para archivos grandes**
```python
NO cargar 1GB+ en RAM de golpe
Procesar en chunks de 10K puntos
```

#### d) **Limpieza automÃ¡tica**
```python
Borrar archivos > 7 dÃ­as
Liberar espacio en disco
Mantener solo datos relevantes
```

---

### 6. **API REST** (`api_example.py`)
**Responsabilidad:** Servir datos a aplicaciones

**Endpoints:**

#### `GET /api/v1/tempo/{pollutant}/latest`
**ParÃ¡metros:**
- `pollutant`: "NO2" | "O3"
- `lat_min`, `lat_max`, `lon_min`, `lon_max` (opcional)
- `quality_threshold`: "STRICT" | "MODERATE" | "PERMISSIVE"

**Respuesta:**
```json
{
  "success": true,
  "pollutant": "NO2",
  "data_quality": {
    "reliability": "BUENA",
    "valid_measurements": 52575,
    "fallback_used": false
  },
  "air_quality": {
    "dominant_category": "Bueno",
    "recommendation": {
      "outdoor_activities": "SEGURO",
      "message": "La calidad del aire es buena...",
      "icon": "âœ…"
    }
  },
  "statistics": {
    "avg_concentration": 0.5,
    "avg_aqi": 2
  },
  "measurements": [...],
  "warning": null
}
```

#### `GET /api/v1/health`
**Respuesta:**
```json
{
  "status": "healthy",
  "system_stats": {
    "total_files": 83,
    "total_size_gb": 2.95
  },
  "recent_data": {
    "files": ["SURFACE_NO2_...json"],
    "count": 3
  }
}
```

---

## ğŸ”„ Pipeline AutomÃ¡tico

### **Flujo de ejecuciÃ³n** (`pipeline_optimizado.py`)

```
CADA 3 HORAS (Windows Task Scheduler):

1. â¬‡ï¸  Descargar archivos nuevos (NASA CMR)
2. ğŸ“‚ Extraer datos de .nc â†’ JSON
3. ğŸ”„ Convertir a superficie + AQI
4. âœ… Validar calidad (fallback si necesario)
5. âœ‚ï¸  Dividir en chunks
6. ğŸ—‘ï¸  Limpiar archivos .nc (ahorrar 300+ MB)
7. ğŸ§¹ Limpiar datos >7 dÃ­as
8. ğŸ“Š Generar estadÃ­sticas
```

**DuraciÃ³n promedio:** 5 minutos  
**Datos procesados:** ~3.7M puntos  
**Chunks generados:** ~77 archivos (~1.1 GB)

---

## ğŸ’¾ Estructura de Archivos

```
TEMPO_Data/
â”œâ”€â”€ .env                          # Credenciales NASA (PRIVADO)
â”œâ”€â”€ tempo_data/                   # Archivos .nc (temporal)
â”‚   â””â”€â”€ [auto-limpiado]
â”‚
â”œâ”€â”€ output/                       # Datos procesados
â”‚   â”œâ”€â”€ NO2_*.json               # ExtracciÃ³n bruta
â”‚   â”œâ”€â”€ O3_*.json                # ExtracciÃ³n bruta
â”‚   â”œâ”€â”€ SURFACE_NO2_*.json       # Con superficie + AQI
â”‚   â”œâ”€â”€ SURFACE_O3_*.json        # Con superficie + AQI
â”‚   â”‚
â”‚   â”œâ”€â”€ chunks/                   # Listos para Cloud
â”‚   â”‚   â”œâ”€â”€ SURFACE_NO2_*_chunk_001_of_002.json
â”‚   â”‚   â”œâ”€â”€ SURFACE_O3_*_chunk_001_of_070.json
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ .cache/                   # CachÃ© interno
â”‚       â””â”€â”€ *.hash
â”‚
â”œâ”€â”€ Scripts de procesamiento:
â”‚   â”œâ”€â”€ descargar_tempo_v2.py
â”‚   â”œâ”€â”€ extraer_datos.py
â”‚   â”œâ”€â”€ convertir_a_superficie.py
â”‚   â”œâ”€â”€ dividir_archivos.py
â”‚   â”œâ”€â”€ quality_manager.py        â­ NUEVO
â”‚   â”œâ”€â”€ datacenter_optimizer.py   â­ NUEVO
â”‚   â”œâ”€â”€ pipeline_optimizado.py    â­ NUEVO
â”‚   â””â”€â”€ api_example.py            â­ NUEVO
â”‚
â””â”€â”€ ConfiguraciÃ³n:
    â”œâ”€â”€ configurar_tarea_automatica.ps1
    â””â”€â”€ README_PIPELINE.md
```

---

## ğŸ“Š MÃ©tricas del Sistema

### **Rendimiento**
- â±ï¸ Descarga: ~2-3 min (228 MB)
- â±ï¸ ExtracciÃ³n: ~1 min
- â±ï¸ ConversiÃ³n: ~1.5 min
- â±ï¸ Chunks: ~30 seg
- **â±ï¸ Total:** ~5 minutos

### **Almacenamiento**
- ğŸ“¥ Input (.nc): ~300 MB (auto-limpiado)
- ğŸ“¤ Output (JSON): ~1.9 GB
- ğŸ“¦ Chunks: ~1.1 GB
- **ğŸ’¾ Total:** ~3 GB por ciclo
- **ğŸ§¹ Auto-limpieza:** Mantiene Ãºltimos 7 dÃ­as

### **Calidad de datos**
- âœ… NO2 V04: 100% quality_flag = 1.0 (52,575 puntos)
- âœ… O3 V04: 100% quality_flag = 1.0 (3,470,799 puntos)
- âš ï¸ NO2 V03 (antiguo): 100% quality_flag = 0.0 â†’ FALLBACK activado

---

## ğŸ” Seguridad y Credenciales

**Archivo `.env`:**
```bash
EARTHDATA_USERNAME=sxbast1ancz
EARTHDATA_PASSWORD=C3B2A1#Sebastian06042004
```

**âš ï¸ CRÃTICO:**
- âŒ NO subir `.env` a GitHub
- âœ… Incluido en `.gitignore`
- âœ… Solo lectura local

---

## ğŸš€ Deployment

### **1. AutomatizaciÃ³n (Windows)**
```powershell
# Ejecutar como Administrador
.\configurar_tarea_automatica.ps1
```

Crea tarea que ejecuta `pipeline_optimizado.py` cada 3 horas.

### **2. Monitoreo**
```powershell
# Ver estado
Get-ScheduledTask -TaskName "TEMPO_Data_Pipeline"

# Ejecutar manualmente
python pipeline_optimizado.py

# Ver logs
python api_example.py
```

### **3. IntegraciÃ³n con Cloud**
```bash
# Subir chunks a Google Cloud Storage
gsutil -m cp output/chunks/*.json gs://your-bucket/tempo/

# O usar Cloud Functions para procesamiento
```

---

## ğŸ“ˆ Escalabilidad

### **Optimizaciones actuales:**
1. âœ… Procesamiento incremental (solo archivos nuevos)
2. âœ… Ãndice espacial para queries rÃ¡pidas
3. âœ… CachÃ© MD5 para evitar reprocesar
4. âœ… Streaming para archivos grandes
5. âœ… Auto-limpieza de datos antiguos

### **PrÃ³ximos pasos (si crece):**
1. âš¡ Multiprocessing paralelo (usar todos los CPUs)
2. ğŸ“Š Base de datos PostgreSQL + PostGIS
3. ğŸ—ºï¸ Servir tiles pre-renderizados
4. ğŸ“¡ WebSocket para updates en tiempo real
5. ğŸ³ Dockerizar todo el pipeline

---

## ğŸ¯ Decisiones de Arquitectura

### **Â¿Por quÃ© CMR API en vez de scraping directo?**
- âœ… MÃ¡s estable y mantenible
- âœ… Endpoints oficiales de NASA
- âœ… Metadata estructurada
- âœ… Menos propenso a romper

### **Â¿Por quÃ© fallback automÃ¡tico?**
- âœ… DÃ­as nublados = datos con quality_flag bajo
- âœ… Mejor entregar datos con advertencia que no entregar nada
- âœ… Usuario decide si confÃ­a o no
- âœ… API marca claramente la confiabilidad

### **Â¿Por quÃ© chunks de 50K puntos?**
- âœ… ~14 MB por chunk (Ã³ptimo para HTTP)
- âœ… FÃ¡cil paralelizar uploads a Cloud
- âœ… No sobrecargar memoria en backend
- âœ… Balanceo entre I/O y tamaÃ±o

### **Â¿Por quÃ© limpiar archivos .nc despuÃ©s?**
- âœ… Ahorra ~300 MB por ciclo
- âœ… Solo necesitamos los JSONs procesados
- âœ… Podemos re-descargar si es necesario

---

## ğŸ“– DocumentaciÃ³n de Referencia

- **NASA TEMPO:** https://tempo.si.edu/
- **NASA Earthdata:** https://urs.earthdata.nasa.gov/
- **CMR API:** https://cmr.earthdata.nasa.gov/search/
- **AQI Guidelines:** https://www.epa.gov/aqi

---

## ğŸ‘¨â€ğŸ’» Autor

Sebastian Cruz  
Fecha: Octubre 4, 2025  
VersiÃ³n: 2.0 Optimizada

---

## âœ… Checklist de ProducciÃ³n

- [x] Descarga automÃ¡tica cada 3 horas
- [x] ValidaciÃ³n de calidad con fallback
- [x] Limpieza automÃ¡tica de espacio
- [x] API REST lista para consumo
- [x] Ãndice espacial para queries rÃ¡pidas
- [x] DocumentaciÃ³n completa
- [x] Manejo de errores robusto
- [ ] Deploy en servidor cloud (pendiente)
- [ ] IntegraciÃ³n con Google Cloud Storage (pendiente)
- [ ] Frontend para visualizaciÃ³n (pendiente)

---

**ğŸ‰ Sistema completamente funcional y listo para producciÃ³n.**
